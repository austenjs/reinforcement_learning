{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\auste\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\auste\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\auste\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\auste\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\auste\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\auste\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\auste\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\auste\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\auste\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\auste\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\auste\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\auste\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#!pip install gym\n",
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "\n",
    "#!pip install keras\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 160, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make('BreakoutDeterministic-v4')\n",
    "observation = env.reset()\n",
    "\n",
    "for i in range(3):\n",
    "    # The ball is released after 2 frames\n",
    "    if i > 1:\n",
    "        print(observation.shape)\n",
    "        plt.imshow(observation)\n",
    "        plt.show()\n",
    "        \n",
    "    # Get the next observation\n",
    "    observation, _, _, _ = env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frame(frame):\n",
    "    frame = frame[30:200, 10:150]\n",
    "    \n",
    "    # grayscale frame and downsize by factor 2\n",
    "    frame = frame[::2, ::2, 0]\n",
    "    \n",
    "    # set background to 0\n",
    "    frame[frame == 144] = 0\n",
    "    frame[frame == 109] = 0\n",
    "    \n",
    "    # set ball and paddles to 1\n",
    "    frame[frame != 0] = 1\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANUAAAD7CAYAAAD95tHFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAMY0lEQVR4nO3dX4xc5X3G8e9TG4dAimxjQK5NulhCBFQVE6wESi+oSSpKIshF0oKSKqpofUNbaCMlpr1oU6lSIlVJuKgqWZCUi5Q/cWhicZHUcoiqXNRhiUkLGAeTuLDBsY2AkPQC1cmvF3OcrNwxe3b33Z2d3e9HGs2cM2f2vKPjx+ec+fNMqgpJ7fzKqAcgLTeGSmrMUEmNGSqpMUMlNWaopMbmFaokNyY5lORwkp2tBiWNs8z1faokq4DvAe8FpoDHgduq6pl2w5PGz+p5PPZdwOGq+j5AkgeBW4AzhmrDhg01MTExj1VKS8ORI0d4+eWXM+y++YRqE/DitOkp4N1v9oCJiQkmJyfnsUppadi2bdsZ75vPOdWwlP6/Y8kkO5JMJpk8ceLEPFYnjYf57KmmgIunTW8GXjp9oaraBewCSFLJ0D2mtGzMZ0/1OHBpkkuSrAFuBfa0GZY0vua8p6qqk0n+FPg6sAr4fFU93Wxk0pia80vqc1pZ4vdMtGxU1dBzGT9RITVmqKTGDJXUmKGSGjNUUmOGSmrMUEmNGSqpMUMlNWaopMYMldSYoZIaM1RSY4ZKasxQSY0ZKqkxQyU1NmOoknw+yfEkT02btz7J3iTPddfrFnaY0vjos6f6Z+DG0+btBPZV1aXAvm5aEj1CVVX/Drxy2uxbgPu72/cDH2g8LmlszbVN6aKqOgpQVUeTXHimBZPsAHbMcT3S2JlPmWYvp5dpLvT6pFGb66t/x5JsBOiuj7cbkjTe5hqqPcBHu9sfBb7aZjjS+JuxTDPJA8D1wAbgGPA3wFeAh4G3Ay8AH6qq01/MGPa3PPzTsnGmMk0baqU5sqFWWiSGSmrMUEmNLfj7VNNdffXV/jyploWF+nlSSUMYKqkxQyU1ZqikxgyV1JihkhozVFJjhkpqzFBJjRkqqTFDJTVmqKTG+pRpXpzksSQHkzyd5M5uvoWa0hB99lQngY9V1eXANcAdSa7AQk1pqD5lmker6jvd7Z8AB4FNWKgpDTWrc6okE8BVwH5OK9QEzlioKa0kvUOV5G3Al4G7qur1WTxuR5LJJJMnTpyYyxilsdIrVEnOYhCoL1bVI93sXoWaVbWrqrZV1bYLLrigxZilJa3Pq38B7gMOVtVnpt1loaY0RJ+OiuuAPwT+K8mT3by/Aj4FPJzkdrpCzYUZojReZgxVVX0LGFoaCNzQdjjS+PMTFVJjhkpqzFBJjRkqqTFDJTVmqKTGDJXUmKGSGjNUUmOGSmrMUEmNGSqpMUMlNWaopMYMldSYoZIaM1RSY306Ks5O8u0k3+0aaj/Zzb8kyf6uofahJGsWfrjS0tdnT/UGsL2qrgS2AjcmuQb4NPDZrqH2VeD2hRumND76NNRWVf20mzyruxSwHdjdzbehVur07f1b1TUpHQf2As8Dr1XVyW6RKQZV0MMea5mmVpReoaqqn1XVVmAz8C7g8mGLneGxlmlqRZnVq39V9RrwTQa//rE2yamKs83AS22HJo2nPq/+XZBkbXf7rcB7GPzyx2PAB7vFbKiVOqkaetT2ywWS32TwQsQqBiF8uKr+LskW4EFgPXAA+EhVvTHD33rzlUljpKqGlszOGKqWDJWWkzOFyk9USI0ZKqkxQyU1ZqikxgyV1JihkhozVFJjhkpqzFBJjRkqqTFDJTVmqKTGDJXUmKGSGjNUUmOGSmrMUEmN9Q5VV1N2IMmj3bQNtdIQs9lT3cmg8OUUG2qlIfqWaW4G3gfc200HG2qlofruqT4HfBz4eTd9PnNoqJ3XSKUx0af37/3A8ap6YvrsIYvO2FA7xzFKY2X1zItwHXBzkpuAs4HzGOy51iZZ3e2tbKiVOn1+9ePuqtpcVRPArcA3qurD2FArDTWf96k+AfxlksMMzrHuazMkabzZUCvNkQ210iIxVFJjhkpqzFBJjRkqqTFDJTVmqKTGDJXUmKGSGjNUUmOGSmrMUEmNGSqpMUMlNWaopMYMldRYn44KkhwBfgL8DDhZVduSrAceAiaAI8DvV9WrCzNMaXzMZk/1O1W1dVor0k5gX1emua+blla8+Rz+3cKgRBMs05R+oW+oCvi3JE8k2dHNu6iqjgJ01xcuxAClcdPrnAq4rqpeSnIhsDfJs31X0IVwx4wLSsvErNuUkvwt8FPgT4Drq+poko3AN6vqshkea5uSlo05tyklOTfJr566Dfwu8BSwh0GJJlimKf3CjHuqJFuAf+0mVwP/UlV/n+R84GHg7cALwIeq6pUZ/pZ7qp5ObZfBD6xoKTrTnsoyzSXKUC19lmlKi8RQSY0ZKqmxvu9TaZF5LjW+3FNJjRkqqTFDJTVmqKTGDJXUmKGSGjNUUmOGSmrMUEmNGSqpMUMlNWaopMYMldRYr1AlWZtkd5JnkxxMcm2S9Un2Jnmuu1630IOVxkHfPdU9wNeq6h3AlcBBbKiVhupT/HIe8F1gS01bOMkhrCjTCjafjootwAngC0kOJLm3qyrr1VCbZEeSySSTcxy7NFb67Km2Af/BoKV2f5J7gNeBP6uqtdOWe7Wq3vS8yj2VlpP57KmmgKmq2t9N7wbeCRzrDvvoro+3GKg07mYMVVX9CHgxyanzpRuAZ7ChVhqqV5lmkq3AvcAa4PvAHzEIpA21WrFsqJUas6FWWiSGSmrMUEmNGSqpMUMlNWaopMYMldSYoZIaM1RSY4ZKasxQSY0ZKqkxQyU1ZqikxgyV1JihkhqbMVRJLkvy5LTL60nuskxTGm5W3/xNsgr4IfBu4A7glar6VJKdwLqq+sQMj/ebv1o2Wn3z9wbg+ar6b+AW4P5u/v3AB+Y+PGn5mG2obgUe6G73KtOUVpreoUqyBrgZ+NJsVmBDrVaa2eypfg/4TlUd66Z7lWlW1a6q2lZV2+Y3VGk8zCZUt/HLQz+wTFMaqm+Z5jnAiwx++ePH3bzzsUxTK5hlmlJjlmlKi8RQSY0ZKqkxQyU1ZqikxgyV1JihkhozVFJjhkpqzFBJjRkqqTFDJTVmqKTGDJXUmKGSGjNUUmOGSmqsV6iS/EWSp5M8leSBJGcnuSTJ/q6h9qGubUla8frUPm8C/hzYVlW/Aaxi0P/3aeCzVXUp8Cpw+0IOVBoXfQ//VgNvTbIaOAc4CmwHdnf321C7AlVV08tyMWOoquqHwD8waEw6CvwYeAJ4rapOdotNAZuGPd4yTa00fQ7/1jHoTb8E+DXgXAbFmqcb+l+NZZpaafoc/r0H+EFVnaiq/wUeAX4LWNsdDgJsBl5aoDFKY6VPqF4ArklyTpIw+OWPZ4DHgA92y9hQK3X6NtR+EvgD4CRwAPhjBudQDwLru3kfqao3Zvg7y+dsVCueDbVSYzbUSovEUEmNGSqpMUMlNWaopMYMldTY6pkXaepl4H+66+VgAz6XpWqhn8+vn+mORX2fCiDJ5HL5HKDPZeka5fPx8E9qzFBJjY0iVLtGsM6F4nNZukb2fBb9nEpa7jz8kxpb1FAluTHJoSSHk+xczHXPV5KLkzyW5GDXLHVnN399kr1dq9Te7pvSYyHJqiQHkjzaTY9lQ1aStUl2J3m22z7XjnK7LFqokqwC/pHBV/GvAG5LcsVirb+Bk8DHqupy4Brgjm78O4F9XavUvm56XNwJHJw2Pa4NWfcAX6uqdwBXMnhOo9surRtx3qQp51rg69Om7wbuXqz1L8Dz+SrwXuAQsLGbtxE4NOqx9Rz/5u4f23bgUSAM3ixdPWx7LdULcB7wA7rXB6bNH9l2WczDv03Ai9Omz9jAtNQlmQCuAvYDF1XVUYDu+sLRjWxWPgd8HPh5N30+PRuylpgtwAngC92h7L1JzmWE22UxQzXsW5Jj99JjkrcBXwbuqqrXRz2euUjyfuB4VT0xffaQRcdh+6wG3gn8U1VdxeBjcCM9BF/MUE0BF0+bHrsGpiRnMQjUF6vqkW72sSQbu/s3AsdHNb5ZuA64OckRBj0j2xnsucaxIWsKmKqq/d30bgYhG9l2WcxQPQ5c2r3CtIZBdfSeRVz/vHRNUvcBB6vqM9Pu2sOgTQrGpFWqqu6uqs1VNcFgO3yjqj7MGDZkVdWPgBeTXNbNOtX2NbrtssgnlTcB3wOeB/561Ce5sxz7bzM4HPpP4MnuchODc5F9wHPd9fpRj3WWz+t64NHu9hbg28Bh4EvAW0Y9vp7PYSsw2W2brwDrRrld/ESF1JifqJAaM1RSY4ZKasxQSY0ZKqkxQyU1ZqikxgyV1Nj/AQHtU2RLqf5fAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs_preprocessed = preprocess_frame(observation)\n",
    "plt.imshow(obs_preprocessed, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQLAgent:\n",
    "    def __init__(self, cols, rows, n_actions, batch_size=32, booleanPrint = True):\n",
    "        self.state_size = (cols, rows, 4)\n",
    "        self.n_actions = n_actions\n",
    "        self.epsilon = 1.\n",
    "        self.epsilon_start, self.epsilon_end = 1.0, 0.1\n",
    "        self.exploration_steps = 1000000.\n",
    "        self.epsilon_decay_step = (self.epsilon_start - self.epsilon_end) / self.exploration_steps\n",
    "        self.batch_size = batch_size\n",
    "        self.discount_factor = 0.99\n",
    "        self.memory = deque(maxlen=400000)\n",
    "        self.model = self.build_model(booleanPrint)\n",
    "        self.target_model = self.build_model(booleanPrint)\n",
    "        self.optimizer = self.optimizer()\n",
    "        self.avg_q_max, self.avg_loss = 0, 0\n",
    "\n",
    "    def optimizer(self):\n",
    "        a = K.placeholder(shape=(None,), dtype='int32')\n",
    "        y = K.placeholder(shape=(None,), dtype='float32')\n",
    "\n",
    "        py_x = self.model.output\n",
    "\n",
    "        a_one_hot = K.one_hot(a, self.n_actions)\n",
    "        q_value = K.sum(py_x * a_one_hot, axis=1)\n",
    "        error = K.abs(y - q_value)\n",
    "\n",
    "        quadratic_part = K.clip(error, 0.0, 1.0)\n",
    "        linear_part = error - quadratic_part\n",
    "        loss = K.mean(0.5 * K.square(quadratic_part) + linear_part)\n",
    "\n",
    "        opt = Adam(lr=0.00025, epsilon=0.01)\n",
    "        updates = opt.get_updates(self.model.trainable_weights, [], loss)\n",
    "        train = K.function([self.model.input, a, y], [loss], updates=updates)\n",
    "\n",
    "        return train\n",
    "\n",
    "    def build_model(self, booleanPrint):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, (8, 8), strides=(4, 4), activation='relu', input_shape=self.state_size))\n",
    "        model.add(Conv2D(64, (4, 4), strides=(2, 2), activation='relu'))\n",
    "        model.add(Conv2D(64, (3, 3), strides=(1, 1), activation='relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(Dense(self.n_actions))\n",
    "        if booleanPrint:\n",
    "            model.summary()\n",
    "        return model\n",
    "\n",
    "    def update_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    def action(self, history):\n",
    "        history = np.float32(history / 255.0)\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.n_actions)\n",
    "        else:\n",
    "            q_value = self.model.predict(history)\n",
    "            return np.argmax(q_value[0])\n",
    "\n",
    "    def replay(self, history, action, reward, next_history, dead):\n",
    "        self.memory.append((history, action, reward, next_history, dead))\n",
    "\n",
    "    def train(self):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "        if self.epsilon > self.epsilon_end:\n",
    "            self.epsilon -= self.epsilon_decay_step\n",
    "\n",
    "        mini_batch = random.sample(self.memory, self.batch_size)\n",
    "        history = np.zeros((self.batch_size, self.state_size[0], self.state_size[1], self.state_size[2]))\n",
    "        next_history = np.zeros((self.batch_size, self.state_size[0], self.state_size[1], self.state_size[2]))\n",
    "        target = np.zeros((self.batch_size,))\n",
    "        action, reward, dead = [], [], []\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            history[i] = np.float32(mini_batch[i][0] / 255.)\n",
    "            next_history[i] = np.float32(mini_batch[i][3] / 255.)\n",
    "            action.append(mini_batch[i][1])\n",
    "            reward.append(mini_batch[i][2])\n",
    "            dead.append(mini_batch[i][4])\n",
    "\n",
    "        target_value = self.target_model.predict(next_history)\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            if dead[i]:\n",
    "                target[i] = reward[i]\n",
    "            else:\n",
    "                target[i] = reward[i] + self.discount_factor * \\\n",
    "                                        np.amax(target_value[i])\n",
    "\n",
    "        loss = self.optimizer([history, action, target])\n",
    "        self.avg_loss += loss[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 20, 16, 32)        8224      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 9, 7, 64)          32832     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 5, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2240)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1147392   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 1,226,915\n",
      "Trainable params: 1,226,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 20, 16, 32)        8224      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 9, 7, 64)          32832     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 5, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2240)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1147392   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 1,226,915\n",
      "Trainable params: 1,226,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\auste\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\auste\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('BreakoutDeterministic-v4')\n",
    "\n",
    "# General settings\n",
    "update_model_rate = 10000\n",
    "cols, rows = 85, 70\n",
    "n_states = 4\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "\n",
    "# Initialization\n",
    "agent = DQLAgent(cols, rows, n_actions=3)\n",
    "scores, episodes = [], []\n",
    "n_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1582; score:  3; q 1.902821; loss 0.464804; steps 225\n",
      "Iteration 0\n",
      "episode 1858; score:  3; q 1.208713; loss 0.371558; steps 276\n",
      "episode 2116; score:  3; q 1.241204; loss 0.347233; steps 258\n",
      "episode 2294; score:  1; q 1.219222; loss 0.348310; steps 178\n",
      "episode 2443; score:  0; q 1.399869; loss 0.350523; steps 149\n",
      "episode 2662; score:  2; q 1.091328; loss 0.364403; steps 219\n",
      "episode 2833; score:  1; q 0.969700; loss 0.355108; steps 171\n",
      "episode 3095; score:  3; q 0.995472; loss 0.368979; steps 262\n",
      "episode 3260; score:  1; q 0.959200; loss 0.333000; steps 165\n",
      "episode 3547; score:  3; q 1.130420; loss 0.332685; steps 287\n",
      "episode 3676; score:  0; q 1.268659; loss 0.346417; steps 129\n",
      "episode 3811; score:  0; q 1.128877; loss 0.358631; steps 135\n",
      "episode 4066; score:  3; q 1.126571; loss 0.324202; steps 255\n",
      "episode 4381; score:  4; q 1.147389; loss 0.344157; steps 315\n",
      "episode 4606; score:  3; q 0.986312; loss 0.329597; steps 225\n",
      "episode 4742; score:  0; q 0.808460; loss 0.362753; steps 136\n",
      "episode 4991; score:  3; q 0.909923; loss 0.333555; steps 249\n",
      "episode 5127; score:  0; q 1.027259; loss 0.356654; steps 136\n",
      "episode 5297; score:  1; q 1.133424; loss 0.313935; steps 170\n",
      "episode 5550; score:  3; q 0.956186; loss 0.335029; steps 253\n",
      "episode 5680; score:  0; q 1.017189; loss 0.366001; steps 130\n",
      "episode 5869; score:  1; q 1.163287; loss 0.315918; steps 189\n",
      "episode 6002; score:  0; q 0.990242; loss 0.335702; steps 133\n",
      "episode 6132; score:  0; q 0.964801; loss 0.335239; steps 130\n",
      "episode 6332; score:  2; q 0.982856; loss 0.356772; steps 200\n",
      "episode 6662; score:  5; q 0.928914; loss 0.319695; steps 330\n",
      "episode 6916; score:  3; q 0.851479; loss 0.324021; steps 254\n",
      "episode 7044; score:  0; q 0.953085; loss 0.331597; steps 128\n",
      "episode 7295; score:  3; q 1.097384; loss 0.332172; steps 251\n",
      "episode 7465; score:  1; q 1.073859; loss 0.302764; steps 170\n",
      "episode 7653; score:  2; q 0.889710; loss 0.331499; steps 188\n",
      "episode 7786; score:  0; q 0.919129; loss 0.361866; steps 133\n",
      "episode 7941; score:  1; q 0.914389; loss 0.306715; steps 155\n",
      "episode 8285; score:  5; q 0.943512; loss 0.360195; steps 344\n",
      "episode 8538; score:  3; q 0.929102; loss 0.366111; steps 253\n",
      "episode 8705; score:  1; q 0.978684; loss 0.331561; steps 167\n",
      "episode 8879; score:  1; q 0.906840; loss 0.312583; steps 174\n",
      "episode 9084; score:  2; q 0.893659; loss 0.337709; steps 205\n",
      "episode 9221; score:  0; q 0.880525; loss 0.327044; steps 137\n",
      "episode 9364; score:  0; q 0.960407; loss 0.357124; steps 143\n",
      "episode 9523; score:  1; q 0.957716; loss 0.337813; steps 159\n",
      "episode 9776; score:  3; q 0.924591; loss 0.350081; steps 253\n",
      "episode 10038; score:  3; q 1.036576; loss 0.324213; steps 262\n",
      "episode 10260; score:  2; q 1.005464; loss 0.321426; steps 222\n",
      "episode 10424; score:  1; q 0.902222; loss 0.331216; steps 164\n",
      "episode 10712; score:  3; q 0.913377; loss 0.350515; steps 288\n",
      "episode 10837; score:  0; q 0.809732; loss 0.338266; steps 125\n",
      "episode 10967; score:  0; q 0.898120; loss 0.288891; steps 130\n",
      "episode 11145; score:  1; q 0.892462; loss 0.326581; steps 178\n",
      "episode 11327; score:  1; q 0.885532; loss 0.378774; steps 182\n",
      "episode 11466; score:  0; q 1.023212; loss 0.327770; steps 139\n",
      "Iteration 50\n",
      "episode 11618; score:  1; q 1.010059; loss 0.331702; steps 152\n",
      "episode 11779; score:  1; q 0.957773; loss 0.341301; steps 161\n",
      "episode 11951; score:  1; q 0.918429; loss 0.336965; steps 172\n",
      "episode 12155; score:  2; q 1.022924; loss 0.351342; steps 204\n",
      "episode 12320; score:  1; q 0.978546; loss 0.339678; steps 165\n",
      "episode 12447; score:  0; q 0.945453; loss 0.314592; steps 127\n",
      "episode 12575; score:  0; q 1.039674; loss 0.355206; steps 128\n",
      "episode 12809; score:  3; q 0.935095; loss 0.337672; steps 234\n",
      "episode 12942; score:  0; q 0.991887; loss 0.310444; steps 133\n",
      "episode 13072; score:  0; q 0.987880; loss 0.376291; steps 130\n",
      "episode 13405; score:  5; q 0.936206; loss 0.339009; steps 333\n",
      "episode 13539; score:  0; q 0.844689; loss 0.302261; steps 134\n",
      "episode 13669; score:  0; q 0.953217; loss 0.320941; steps 130\n",
      "episode 13826; score:  1; q 0.875494; loss 0.352301; steps 157\n",
      "episode 13981; score:  1; q 0.984019; loss 0.334444; steps 155\n",
      "episode 14137; score:  1; q 1.094189; loss 0.326179; steps 156\n",
      "episode 14351; score:  3; q 0.921743; loss 0.319478; steps 214\n",
      "episode 14581; score:  3; q 1.028836; loss 0.337597; steps 230\n",
      "episode 14765; score:  2; q 1.059705; loss 0.318349; steps 184\n",
      "episode 14924; score:  1; q 0.860828; loss 0.342588; steps 159\n",
      "episode 15150; score:  2; q 0.912700; loss 0.341011; steps 226\n",
      "episode 15361; score:  3; q 0.917398; loss 0.351629; steps 211\n",
      "episode 15630; score:  4; q 0.895894; loss 0.343412; steps 269\n",
      "episode 15799; score:  1; q 0.918428; loss 0.356216; steps 169\n",
      "episode 15960; score:  1; q 1.009018; loss 0.345074; steps 161\n",
      "episode 16087; score:  0; q 0.905739; loss 0.376769; steps 127\n",
      "episode 16307; score:  2; q 0.948960; loss 0.343032; steps 220\n",
      "episode 16451; score:  0; q 0.727179; loss 0.334374; steps 144\n",
      "episode 16581; score:  0; q 0.741439; loss 0.351466; steps 130\n",
      "episode 16707; score:  0; q 0.928911; loss 0.318715; steps 126\n",
      "episode 16834; score:  0; q 0.937087; loss 0.318861; steps 127\n",
      "episode 17013; score:  1; q 0.855191; loss 0.315329; steps 179\n",
      "episode 17150; score:  0; q 0.878001; loss 0.358441; steps 137\n",
      "episode 17351; score:  2; q 0.788519; loss 0.362540; steps 201\n",
      "episode 17567; score:  3; q 0.828946; loss 0.322412; steps 216\n",
      "episode 17697; score:  0; q 0.974239; loss 0.341046; steps 130\n",
      "episode 17974; score:  3; q 1.012877; loss 0.311442; steps 277\n",
      "episode 18177; score:  2; q 0.983831; loss 0.326732; steps 203\n",
      "episode 18392; score:  2; q 0.957177; loss 0.350352; steps 215\n",
      "episode 18568; score:  1; q 0.972338; loss 0.336524; steps 176\n",
      "episode 18730; score:  1; q 0.961594; loss 0.364987; steps 162\n",
      "episode 18969; score:  3; q 0.812012; loss 0.370843; steps 239\n",
      "episode 19112; score:  0; q 0.949642; loss 0.311563; steps 143\n",
      "episode 19244; score:  0; q 0.987407; loss 0.285828; steps 132\n",
      "episode 19453; score:  2; q 0.926210; loss 0.287373; steps 209\n",
      "episode 19728; score:  4; q 0.910045; loss 0.348559; steps 275\n",
      "episode 19979; score:  3; q 0.958517; loss 0.330038; steps 251\n",
      "episode 20106; score:  0; q 0.975135; loss 0.341167; steps 127\n",
      "episode 20287; score:  1; q 0.925041; loss 0.331687; steps 181\n",
      "episode 20429; score:  0; q 0.986908; loss 0.315611; steps 142\n",
      "Iteration 100\n",
      "episode 20565; score:  0; q 0.902560; loss 0.356690; steps 136\n",
      "episode 20770; score:  2; q 0.857260; loss 0.333875; steps 205\n",
      "episode 21045; score:  3; q 0.918147; loss 0.365614; steps 275\n",
      "episode 21221; score:  1; q 0.925003; loss 0.328488; steps 176\n",
      "episode 21360; score:  0; q 0.837886; loss 0.336180; steps 139\n",
      "episode 21534; score:  1; q 0.840913; loss 0.334453; steps 174\n",
      "episode 21686; score:  1; q 0.943027; loss 0.343378; steps 152\n",
      "episode 21920; score:  3; q 0.985003; loss 0.323243; steps 234\n",
      "episode 22108; score:  2; q 0.972225; loss 0.369071; steps 188\n",
      "episode 22337; score:  3; q 0.929586; loss 0.355447; steps 229\n",
      "episode 22523; score:  2; q 0.916401; loss 0.340204; steps 186\n",
      "episode 22652; score:  0; q 0.883924; loss 0.332627; steps 129\n",
      "episode 22777; score:  0; q 0.958160; loss 0.300593; steps 125\n",
      "episode 22978; score:  2; q 0.929086; loss 0.333946; steps 201\n",
      "episode 23112; score:  0; q 1.019960; loss 0.343456; steps 134\n",
      "episode 23240; score:  0; q 0.901425; loss 0.343425; steps 128\n",
      "episode 23374; score:  0; q 0.914581; loss 0.376231; steps 134\n",
      "episode 23551; score:  1; q 0.906891; loss 0.321524; steps 177\n",
      "episode 23784; score:  2; q 1.018830; loss 0.342832; steps 233\n",
      "episode 23910; score:  0; q 0.909483; loss 0.323765; steps 126\n",
      "episode 24095; score:  1; q 0.981653; loss 0.347984; steps 185\n",
      "episode 24230; score:  0; q 0.945582; loss 0.355417; steps 135\n",
      "episode 24384; score:  1; q 0.875348; loss 0.348619; steps 154\n",
      "episode 24590; score:  2; q 0.891578; loss 0.337781; steps 206\n",
      "episode 24813; score:  2; q 0.840603; loss 0.339822; steps 223\n",
      "episode 24982; score:  1; q 0.872759; loss 0.301709; steps 169\n",
      "episode 25202; score:  2; q 0.820573; loss 0.355420; steps 220\n",
      "episode 25336; score:  0; q 0.963214; loss 0.355788; steps 134\n",
      "episode 25585; score:  3; q 0.919184; loss 0.324556; steps 249\n",
      "episode 25728; score:  0; q 0.915208; loss 0.344654; steps 143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 26002; score:  3; q 0.876879; loss 0.346821; steps 274\n",
      "episode 26251; score:  3; q 0.816635; loss 0.354114; steps 249\n",
      "episode 26420; score:  1; q 0.889423; loss 0.342664; steps 169\n",
      "episode 26551; score:  0; q 0.790869; loss 0.340333; steps 131\n",
      "episode 26723; score:  1; q 0.790705; loss 0.363580; steps 172\n",
      "episode 26947; score:  2; q 0.877435; loss 0.323445; steps 224\n",
      "episode 27117; score:  1; q 0.853827; loss 0.331229; steps 170\n",
      "episode 27292; score:  1; q 0.921011; loss 0.339368; steps 175\n",
      "episode 27428; score:  0; q 0.940601; loss 0.341341; steps 136\n",
      "episode 27611; score:  1; q 0.913975; loss 0.329512; steps 183\n",
      "episode 27789; score:  1; q 0.917739; loss 0.343918; steps 178\n",
      "episode 27972; score:  1; q 0.863972; loss 0.355837; steps 183\n",
      "episode 28126; score:  1; q 0.894794; loss 0.295610; steps 154\n",
      "episode 28304; score:  1; q 0.841191; loss 0.332218; steps 178\n",
      "episode 28538; score:  3; q 0.841378; loss 0.347337; steps 234\n",
      "episode 28738; score:  2; q 0.818583; loss 0.326469; steps 200\n",
      "episode 28894; score:  1; q 0.734632; loss 0.328042; steps 156\n",
      "episode 29023; score:  0; q 0.795510; loss 0.303073; steps 129\n",
      "episode 29199; score:  1; q 0.891265; loss 0.349495; steps 176\n",
      "episode 29429; score:  3; q 0.934717; loss 0.319424; steps 230\n",
      "Iteration 150\n",
      "episode 29562; score:  0; q 0.990213; loss 0.334974; steps 133\n",
      "episode 29749; score:  2; q 0.849370; loss 0.324456; steps 187\n",
      "episode 29875; score:  0; q 0.880690; loss 0.367743; steps 126\n",
      "episode 30078; score:  2; q 0.902840; loss 0.344108; steps 203\n",
      "episode 30282; score:  2; q 0.910483; loss 0.343672; steps 204\n",
      "episode 30437; score:  1; q 0.887319; loss 0.355286; steps 155\n",
      "episode 30565; score:  0; q 0.953276; loss 0.361333; steps 128\n",
      "episode 30740; score:  1; q 0.951667; loss 0.335398; steps 175\n",
      "episode 30869; score:  0; q 0.911314; loss 0.346702; steps 129\n",
      "episode 31065; score:  2; q 0.940520; loss 0.314745; steps 196\n",
      "episode 31228; score:  1; q 0.891924; loss 0.344842; steps 163\n",
      "episode 31361; score:  0; q 0.985393; loss 0.334266; steps 133\n",
      "episode 31534; score:  1; q 0.869834; loss 0.322935; steps 173\n",
      "episode 31811; score:  3; q 0.843258; loss 0.339845; steps 277\n",
      "episode 31994; score:  1; q 0.789136; loss 0.320754; steps 183\n",
      "episode 32122; score:  0; q 0.781090; loss 0.343344; steps 128\n",
      "episode 32256; score:  0; q 0.874911; loss 0.325033; steps 134\n",
      "episode 32474; score:  2; q 0.840643; loss 0.345525; steps 218\n",
      "episode 32612; score:  0; q 0.967983; loss 0.364968; steps 138\n",
      "episode 32741; score:  0; q 0.941535; loss 0.347917; steps 129\n",
      "episode 32871; score:  0; q 1.027430; loss 0.335905; steps 130\n",
      "episode 33032; score:  1; q 0.904909; loss 0.320562; steps 161\n",
      "episode 33165; score:  0; q 0.867779; loss 0.368756; steps 133\n",
      "episode 33319; score:  1; q 0.928887; loss 0.334044; steps 154\n",
      "episode 33478; score:  1; q 0.999931; loss 0.326558; steps 159\n",
      "episode 33634; score:  1; q 0.995231; loss 0.326544; steps 156\n",
      "episode 33837; score:  2; q 0.921309; loss 0.318013; steps 203\n",
      "episode 34101; score:  4; q 0.858902; loss 0.309227; steps 264\n",
      "episode 34256; score:  1; q 0.976234; loss 0.326000; steps 155\n",
      "episode 34427; score:  1; q 0.928616; loss 0.305807; steps 171\n",
      "episode 34555; score:  0; q 0.843116; loss 0.371900; steps 128\n",
      "episode 34686; score:  0; q 0.845002; loss 0.321371; steps 131\n",
      "episode 34895; score:  2; q 0.905379; loss 0.373925; steps 209\n",
      "episode 35020; score:  0; q 0.865239; loss 0.326793; steps 125\n",
      "episode 35242; score:  2; q 0.926055; loss 0.328787; steps 222\n",
      "episode 35448; score:  2; q 0.919461; loss 0.347663; steps 206\n",
      "episode 35619; score:  1; q 0.938976; loss 0.343007; steps 171\n",
      "episode 35880; score:  4; q 0.933896; loss 0.351517; steps 261\n",
      "episode 36057; score:  1; q 0.921638; loss 0.346328; steps 177\n",
      "episode 36194; score:  0; q 0.934779; loss 0.361178; steps 137\n",
      "episode 36337; score:  0; q 0.884536; loss 0.329902; steps 143\n",
      "episode 36472; score:  0; q 0.832366; loss 0.338553; steps 135\n",
      "episode 36608; score:  0; q 0.889621; loss 0.331037; steps 136\n",
      "episode 36867; score:  3; q 0.884573; loss 0.356574; steps 259\n",
      "episode 37032; score:  1; q 0.818729; loss 0.336490; steps 165\n",
      "episode 37263; score:  3; q 0.813350; loss 0.349223; steps 231\n",
      "episode 37446; score:  1; q 0.959754; loss 0.323514; steps 183\n",
      "episode 37627; score:  1; q 0.869133; loss 0.352425; steps 181\n",
      "episode 37935; score:  4; q 0.860859; loss 0.339382; steps 308\n",
      "episode 38068; score:  0; q 0.859838; loss 0.355277; steps 133\n"
     ]
    }
   ],
   "source": [
    "iteration = 0 \n",
    "while True:\n",
    "    done = False\n",
    "    dead = False\n",
    "    step, score, start_life = 0, 0, 5\n",
    "    observation = env.reset()\n",
    "\n",
    "\n",
    "    state = preprocess_frame(observation)\n",
    "    history = np.stack((state, state, state, state), axis=2)\n",
    "    history = np.reshape([history], (1, cols, rows, n_states))\n",
    "\n",
    "    while not done:\n",
    "#       env.render()\n",
    "        n_steps += 1\n",
    "        step += 1\n",
    "        \n",
    "        # Get action\n",
    "        action = agent.action(history)\n",
    "        observation, reward, done, info = env.step(action+1)\n",
    "        \n",
    "        # Extract next state\n",
    "        state_next = preprocess_frame(observation)\n",
    "        state_next = np.reshape([state_next], (1, cols, rows, 1))\n",
    "        history_next = np.append(state_next, history[:, :, :, :3], axis=3)\n",
    "\n",
    "        agent.avg_q_max += np.amax(agent.model.predict(history)[0])\n",
    "        reward = np.clip(reward, -1., 1.)\n",
    "\n",
    "        agent.replay(history, action, reward, history_next, dead)\n",
    "        agent.train()\n",
    "        if n_steps % update_model_rate == 0:\n",
    "            agent.update_model()\n",
    "        score += reward\n",
    "\n",
    "        if dead:\n",
    "            dead = False\n",
    "        else:\n",
    "            history = history_next\n",
    "\n",
    "        if done:\n",
    "            print('episode {:2d}; score: {:2.0f}; q {:2f}; loss {:2f}; steps {}'\n",
    "                  .format(n_steps, score, agent.avg_q_max / float(step), agent.avg_loss / float(step), step))\n",
    "\n",
    "            agent.avg_q_max, agent.avg_loss = 0, 0\n",
    "    \n",
    "    # Save weights of model\n",
    "    if iteration == 200: #train 200 times\n",
    "        agent.model.save_weights(\"breakout_dql.h5\")\n",
    "        break\n",
    "    if iteration % 50 == 0:\n",
    "        print(f'Iteration {iteration}')\n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('BreakoutDeterministic-v4')\n",
    "agent = DQLAgent(cols, rows, n_actions=3, booleanPrint = False)\n",
    "\n",
    "for i in range(5):\n",
    "    observation = env.reset()\n",
    "\n",
    "    state = preprocess_frame(observation)\n",
    "    history = np.stack((state, state, state, state), axis=2)\n",
    "    history = np.reshape([history], (1, cols, rows, n_states))\n",
    "    done = False\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = agent.action(history)\n",
    "        observe, reward, done, info = env.step(action+1)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
